{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-02T19:39:56.104560Z",
     "start_time": "2025-07-02T19:39:55.149769Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:39:59.901109Z",
     "start_time": "2025-07-02T19:39:59.872484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Creamos un diccionario con datos de ejemplo\n",
    "data = {\n",
    "    'ID_Cliente': [101, 102, 103, 104, 105, 101, 106, 107, 108, 109],\n",
    "    'Region': ['Norte', 'Sur', 'Este', 'Norte', 'Oeste', 'Norte', 'Sur', 'Este', np.nan, 'Oeste'],\n",
    "    'Producto': ['A', 'B', 'A', 'C', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
    "    'Unidades': [10, 5, 8, 12, 5, 10, 15, 9, 7, np.nan],\n",
    "    'Precio_Total': [150.0, 200.5, 120.0, 300.0, 210.5, 150.0, 450.0, 180.5, 105.0, 250.0]\n",
    "}\n",
    "\n",
    "# Convertimos el diccionario a un DataFrame de Pandas\n",
    "df_origen = pd.DataFrame(data)\n",
    "\n",
    "# Guardamos el DataFrame en un archivo CSV\n",
    "df_origen.to_csv('dataset_ventas.csv', index=False)\n",
    "\n",
    "print(\"El archivo 'dataset_ventas.csv' ha sido creado.\")"
   ],
   "id": "fb701a56f58b3e58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo 'dataset_ventas.csv' ha sido creado.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Carga y Exploración de Datos",
   "id": "b733dc088effc2ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:40:57.338017Z",
     "start_time": "2025-07-02T19:40:57.295721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1.a. Importa un dataset en formato CSV en un DataFrame.\n",
    "df = pd.read_csv('dataset_ventas.csv')\n",
    "\n",
    "print(\"---  ---\")\n",
    "\n",
    "# 1.b. Inspecciona los datos con .head(), .info() y .describe().\n",
    "print(\"\\nInspección con .head() (primeras 5 filas):\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInspección con .info() (tipos de datos y valores no nulos):\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nInspección con .describe() (estadísticas descriptivas para columnas numéricas):\")\n",
    "print(df.describe())\n",
    "\n",
    "# 1.c. Identifica valores nulos y duplicados.\n",
    "print(\"\\nConteo de valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(f\"\\nNúmero total de filas duplicadas: {df.duplicated().sum()}\")"
   ],
   "id": "c286474815e2e73d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Carga y Exploración de Datos ---\n",
      "\n",
      "Inspección con .head() (primeras 5 filas):\n",
      "   ID_Cliente Region Producto  Unidades  Precio_Total\n",
      "0         101  Norte        A      10.0         150.0\n",
      "1         102    Sur        B       5.0         200.5\n",
      "2         103   Este        A       8.0         120.0\n",
      "3         104  Norte        C      12.0         300.0\n",
      "4         105  Oeste        B       5.0         210.5\n",
      "\n",
      "Inspección con .info() (tipos de datos y valores no nulos):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID_Cliente    10 non-null     int64  \n",
      " 1   Region        9 non-null      object \n",
      " 2   Producto      10 non-null     object \n",
      " 3   Unidades      9 non-null      float64\n",
      " 4   Precio_Total  10 non-null     float64\n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 528.0+ bytes\n",
      "\n",
      "Inspección con .describe() (estadísticas descriptivas para columnas numéricas):\n",
      "       ID_Cliente  Unidades  Precio_Total\n",
      "count   10.000000   9.00000     10.000000\n",
      "mean   104.600000   9.00000    211.650000\n",
      "std      2.875181   3.24037    102.501233\n",
      "min    101.000000   5.00000    105.000000\n",
      "25%    102.250000   7.00000    150.000000\n",
      "50%    104.500000   9.00000    190.500000\n",
      "75%    106.750000  10.00000    240.125000\n",
      "max    109.000000  15.00000    450.000000\n",
      "\n",
      "Conteo de valores nulos por columna:\n",
      "ID_Cliente      0\n",
      "Region          1\n",
      "Producto        0\n",
      "Unidades        1\n",
      "Precio_Total    0\n",
      "dtype: int64\n",
      "\n",
      "Número total de filas duplicadas: 1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Limpieza y Transformación de Datos",
   "id": "2af58366fa5b5a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:45:18.268384Z",
     "start_time": "2025-07-02T19:45:18.243989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Hacemos una copia para no alterar el DataFrame original cargado\n",
    "df_limpio = df.copy()\n",
    "\n",
    "# 2.a. Imputa valores nulos utilizando estrategias adecuadas.\n",
    "# Para la columna numérica 'Unidades', usamos la mediana, que es robusta a outliers.\n",
    "mediana_unidades = df_limpio['Unidades'].median()\n",
    "df_limpio['Unidades'].fillna(mediana_unidades, inplace=True)\n",
    "print(f\"\\nValor nulo en 'Unidades' imputado con la mediana ({mediana_unidades}).\")\n",
    "\n",
    "# Para la columna categórica 'Region', usamos la moda (el valor más frecuente).\n",
    "moda_region = df_limpio['Region'].mode()[0]\n",
    "df_limpio['Region'].fillna(moda_region, inplace=True)\n",
    "print(f\"Valor nulo en 'Region' imputado con la moda ('{moda_region}').\")\n",
    "\n",
    "# Verificamos que ya no hay nulos\n",
    "print(\"\\nConteo de nulos después de la imputación:\")\n",
    "print(df_limpio.isnull().sum())\n",
    "\n",
    "# 2.b. Elimina registros duplicados.\n",
    "df_limpio.drop_duplicates(inplace=True)\n",
    "print(\"\\nRegistros duplicados eliminados.\")\n",
    "print(f\"Número de filas después de eliminar duplicados: {len(df_limpio)}\")\n",
    "\n",
    "# 2.c. Convierte columnas categóricas en variables numéricas si es necesario.\n",
    "# La columna 'Region' es categórica. Usaremos One-Hot Encoding para convertirla\n",
    "# en variables numéricas, lo cual es ideal para algoritmos de machine learning.\n",
    "df_limpio = pd.get_dummies(df_limpio, columns=['Region'], prefix='R')\n",
    "print(\"\\nColumnas categóricas convertidas a numéricas con One-Hot Encoding:\")\n",
    "print(df_limpio)"
   ],
   "id": "eef82c33c80d70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Limpieza y Transformación de Datos ---\n",
      "\n",
      "Valor nulo en 'Unidades' imputado con la mediana (9.0).\n",
      "Valor nulo en 'Region' imputado con la moda ('Norte').\n",
      "\n",
      "Conteo de nulos después de la imputación:\n",
      "ID_Cliente      0\n",
      "Region          0\n",
      "Producto        0\n",
      "Unidades        0\n",
      "Precio_Total    0\n",
      "dtype: int64\n",
      "\n",
      "Registros duplicados eliminados.\n",
      "Número de filas después de eliminar duplicados: 9\n",
      "\n",
      "Columnas categóricas convertidas a numéricas con One-Hot Encoding:\n",
      "   ID_Cliente Producto  Unidades  Precio_Total  R_Este  R_Norte  R_Oeste  \\\n",
      "0         101        A      10.0         150.0   False     True    False   \n",
      "1         102        B       5.0         200.5   False    False    False   \n",
      "2         103        A       8.0         120.0    True    False    False   \n",
      "3         104        C      12.0         300.0   False     True    False   \n",
      "4         105        B       5.0         210.5   False    False     True   \n",
      "6         106        C      15.0         450.0   False    False    False   \n",
      "7         107        B       9.0         180.5    True    False    False   \n",
      "8         108        A       7.0         105.0   False     True    False   \n",
      "9         109        C       9.0         250.0   False    False     True   \n",
      "\n",
      "   R_Sur  \n",
      "0  False  \n",
      "1   True  \n",
      "2  False  \n",
      "3  False  \n",
      "4  False  \n",
      "6   True  \n",
      "7  False  \n",
      "8  False  \n",
      "9  False  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_24204\\1182285569.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_limpio['Unidades'].fillna(mediana_unidades, inplace=True)\n",
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_24204\\1182285569.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_limpio['Region'].fillna(moda_region, inplace=True)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Optimización y Estructuración de Datos",
   "id": "caf4bdf4186eefdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:52:09.561802Z",
     "start_time": "2025-07-02T19:52:09.535018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_optimizado = df_limpio.copy()\n",
    "\n",
    "# 3.a. Aplica funciones de groupby y agregación.\n",
    "# Vamos a agrupar por 'Producto' y calcular el total de unidades vendidas y el promedio del precio.\n",
    "resumen_por_producto = df_optimizado.groupby('Producto').agg(\n",
    "    Total_Unidades=('Unidades', 'sum'),\n",
    "    Precio_Promedio=('Precio_Total', 'mean')\n",
    ")\n",
    "print(\"\\nAgregación de datos por producto:\")\n",
    "print(resumen_por_producto)\n",
    "\n",
    "# 3.b. Filtra los datos para obtener subconjuntos de interés.\n",
    "# Vamos a quedarnos solo con las ventas cuyo precio total fue mayor a 200.\n",
    "ventas_grandes = df_optimizado[df_optimizado['Precio_Total'] > 200].copy()\n",
    "print(\"\\nSubconjunto de datos filtrado (ventas con Precio_Total > 200):\")\n",
    "print(ventas_grandes)\n",
    "\n",
    "# 3.c. Renombra y reorganiza columnas para mejorar la interpretación.\n",
    "# Vamos a trabajar con el dataframe 'ventas_grandes'\n",
    "ventas_grandes.rename(columns={\n",
    "    'ID_Cliente': 'ID Cliente',\n",
    "    'Producto': 'SKU',\n",
    "    'Unidades': 'Nro Unidades',\n",
    "    'Precio_Total': 'Venta Bruta'\n",
    "}, inplace=True)\n",
    "\n",
    "# Reorganizamos el orden de las columnas para que sea más lógico\n",
    "columnas_ordenadas = [\n",
    "    'ID Cliente', 'SKU', 'Nro Unidades', 'Venta Bruta',\n",
    "    'R_Este', 'R_Norte', 'R_Oeste', 'R_Sur'\n",
    "]\n",
    "ventas_grandes = ventas_grandes[columnas_ordenadas]\n",
    "print(\"\\nDataFrame final con columnas renombradas y reorganizadas:\")\n",
    "print(ventas_grandes)"
   ],
   "id": "8b24cc4494d0018c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Optimización y Estructuración de Datos ---\n",
      "\n",
      "Agregación de datos por producto:\n",
      "          Total_Unidades  Precio_Promedio\n",
      "Producto                                 \n",
      "A                   25.0       125.000000\n",
      "B                   19.0       197.166667\n",
      "C                   36.0       333.333333\n",
      "\n",
      "Subconjunto de datos filtrado (ventas con Precio_Total > 200):\n",
      "   ID_Cliente Producto  Unidades  Precio_Total  R_Este  R_Norte  R_Oeste  \\\n",
      "1         102        B       5.0         200.5   False    False    False   \n",
      "3         104        C      12.0         300.0   False     True    False   \n",
      "4         105        B       5.0         210.5   False    False     True   \n",
      "6         106        C      15.0         450.0   False    False    False   \n",
      "9         109        C       9.0         250.0   False    False     True   \n",
      "\n",
      "   R_Sur  \n",
      "1   True  \n",
      "3  False  \n",
      "4  False  \n",
      "6   True  \n",
      "9  False  \n",
      "\n",
      "DataFrame final con columnas renombradas y reorganizadas:\n",
      "   ID Cliente SKU  Nro Unidades  Venta Bruta  R_Este  R_Norte  R_Oeste  R_Sur\n",
      "1         102   B           5.0        200.5   False    False    False   True\n",
      "3         104   C          12.0        300.0   False     True    False  False\n",
      "4         105   B           5.0        210.5   False    False     True  False\n",
      "6         106   C          15.0        450.0   False    False    False   True\n",
      "9         109   C           9.0        250.0   False    False     True  False\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Exportación de Datos",
   "id": "ee3efec721e0397f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T19:52:31.848510Z",
     "start_time": "2025-07-02T19:52:31.443604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Usaremos el DataFrame 'ventas_grandes' como nuestro resultado final a exportar.\n",
    "\n",
    "# 4.a. Guarda el DataFrame procesado en un archivo CSV sin incluir el índice.\n",
    "ventas_grandes.to_csv('reporte_ventas_filtrado.csv', index=False)\n",
    "print(\"\\nDataFrame procesado guardado en 'reporte_ventas_filtrado.csv'\")\n",
    "\n",
    "# 4.b. Exporta los datos limpios a Excel para su visualización y reporte.\n",
    "ventas_grandes.to_excel('reporte_ventas_filtrado.xlsx', index=False, sheet_name='Ventas Clave')\n",
    "print(\"DataFrame procesado exportado a 'reporte_ventas_filtrado.xlsx'\")"
   ],
   "id": "d3e0f8f62bdcd244",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Exportación de Datos ---\n",
      "\n",
      "DataFrame procesado guardado en 'reporte_ventas_filtrado.csv'\n",
      "DataFrame procesado exportado a 'reporte_ventas_filtrado.xlsx'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8f207a26ad46d6f1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
