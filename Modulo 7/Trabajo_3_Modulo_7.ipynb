{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PNFY6OvK6LG4"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Iniciar SparkSession y Crear Datos de Ejemplo\n",
        "spark = SparkSession.builder.appName(\"PurchasePrediction\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (1, 10, 5, 3, \"electronica\", 1), (2, 2, 25, 8, \"hogar\", 1),\n",
        "    (3, 30, 8, 1, \"moda\", 0), (4, 1, 15, 12, \"electronica\", 1),\n",
        "    (5, 45, 2, 0, \"libros\", 0), (6, 8, 18, 6, \"hogar\", 1),\n",
        "    (7, 90, 1, 0, \"moda\", 0), (8, 5, 30, 10, \"electronica\", 1),\n",
        "    (9, 60, 3, 1, \"hogar\", 0), (10, 15, 12, 4, \"libros\", 0)\n",
        "]\n",
        "columns = [\"id_cliente\", \"dias_ultima_visita\", \"paginas_vistas\", \"compras_mes_anterior\", \"ultimo_producto_visto\", \"comprara_prox_dias\"]\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# La columna objetivo debe llamarse \"label\" para los evaluadores de MLlib\n",
        "df = df.withColumnRenamed(\"comprara_prox_dias\", \"label\")\n",
        "\n",
        "# 2. Definir Pipeline de Transformación y Vectorización\n",
        "# Columnas categóricas y numéricas\n",
        "categorical_cols = [\"ultimo_producto_visto\"]\n",
        "numerical_cols = [\"dias_ultima_visita\", \"paginas_vistas\", \"compras_mes_anterior\"]\n",
        "\n",
        "# Etapa 1: Convertir strings a índices numéricos\n",
        "string_indexer = StringIndexer(inputCols=categorical_cols, outputCols=[c + \"_index\" for c in categorical_cols])\n",
        "# Etapa 2: One-Hot Encoding\n",
        "one_hot_encoder = OneHotEncoder(inputCols=string_indexer.getOutputCols(), outputCols=[c + \"_ohe\" for c in categorical_cols])\n",
        "# Etapa 3: Ensamblar todas las características en un solo vector\n",
        "assembler_inputs = numerical_cols + one_hot_encoder.getOutputCols()\n",
        "vector_assembler = VectorAssembler(inputCols=assembler_inputs, outputCol=\"features\")\n",
        "\n",
        "# Se crea un pipeline solo para el preprocesamiento\n",
        "preprocessing_pipeline = Pipeline(stages=[string_indexer, one_hot_encoder, vector_assembler])\n",
        "\n",
        "# 3. Implementar el Modelo Supervisado (Random Forest)\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "# 4. Dividir los datos\n",
        "(training_data, test_data) = df.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "gNj8c7886QiQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Ajustar Hiperparámetros con Validación Cruzada\n",
        "# Se define una grilla de parámetros para probar\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [10, 20])\n",
        "             .addGrid(rf.maxDepth, [5, 10])\n",
        "             .build())\n",
        "\n",
        "# Se define el evaluador que medirá el rendimiento\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
        "\n",
        "# Se crea el CrossValidator\n",
        "cv = CrossValidator(estimator=rf,\n",
        "                    estimatorParamMaps=paramGrid,\n",
        "                    evaluator=evaluator,\n",
        "                    numFolds=3) # Usar 3 folds para validación cruzada\n",
        "\n",
        "# Se crea el Pipeline final que une el preprocesamiento y el modelo con CrossValidator\n",
        "final_pipeline = Pipeline(stages=[preprocessing_pipeline, cv])\n",
        "\n",
        "# Entrenar el pipeline completo. Esto ejecuta la validación cruzada para encontrar el mejor modelo.\n",
        "pipeline_model = final_pipeline.fit(training_data)"
      ],
      "metadata": {
        "id": "n8ImMOGi6URk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Realizar Predicciones y Evaluar el Desempeño\n",
        "predictions = pipeline_model.transform(test_data)\n",
        "\n",
        "# Evaluar con AUC-ROC\n",
        "roc_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "# Evaluar con Precisión-Recall\n",
        "evaluator.setMetricName(\"areaUnderPR\")\n",
        "pr_auc = evaluator.evaluate(predictions)\n",
        "\n",
        "# 7. Mostrar Resultados\n",
        "print(\"\\n--- Resultados de la Evaluación del Modelo ---\")\n",
        "print(f\"Área bajo la curva ROC (AUC-ROC) en datos de prueba: {roc_auc:.4f}\")\n",
        "print(f\"Área bajo la curva de Precisión-Recall (AUC-PR) en datos de prueba: {pr_auc:.4f}\")\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "haCNAhiy6WKE",
        "outputId": "7164a692-bcf5-491b-a89e-304507aa153e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Resultados de la Evaluación del Modelo ---\n",
            "Área bajo la curva ROC (AUC-ROC) en datos de prueba: 1.0000\n",
            "Área bajo la curva de Precisión-Recall (AUC-PR) en datos de prueba: 1.0000\n"
          ]
        }
      ]
    }
  ]
}