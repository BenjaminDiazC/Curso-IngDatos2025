{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e16d142",
   "metadata": {},
   "source": [
    "\n",
    "# Spark — Reviews con **UDF** (Windows-friendly)\n",
    "\n",
    "Este notebook carga un CSV de reseñas (`reviews.csv`) y usa una **UDF de PySpark** para contar palabras por fila.  \n",
    "Incluye ajustes para Windows que evitan el error `Python worker failed to connect back`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d1448",
   "metadata": {},
   "source": [
    "\n",
    "## 0) (Windows) Usar el mismo Python para driver y ejecutores\n",
    "\n",
    "Ejecuta esta celda **antes** de crear la `SparkSession`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdaf83bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYSPARK_PYTHON = c:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n",
      "PYSPARK_DRIVER_PYTHON = c:\\Users\\patri\\AppData\\Local\\Programs\\Python\\Python310\\python.exe\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "print(\"PYSPARK_PYTHON =\", os.environ.get(\"PYSPARK_PYTHON\"))\n",
    "print(\"PYSPARK_DRIVER_PYTHON =\", os.environ.get(\"PYSPARK_DRIVER_PYTHON\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba9059",
   "metadata": {},
   "source": [
    "## 1) Crear SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5290db5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://host.docker.internal:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>UDF_Reviews_Windows</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1dcff421180>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import sys\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"UDF_Reviews_Windows\")\n",
    "         # Evita problemas con antivirus/firewall en Windows\n",
    "         .config(\"spark.python.use.daemon\",\"false\")\n",
    "         # Propaga el mismo intérprete de Python a los ejecutores\n",
    "         .config(\"spark.executorEnv.PYSPARK_PYTHON\", sys.executable)\n",
    "         .getOrCreate())\n",
    "\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9c947",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Cargar `reviews.csv` (o generar uno de ejemplo)\n",
    "\n",
    "- Estructura mínima esperada: `review_id, review_text`.  \n",
    "- Si el archivo no existe en la ruta indicada, se crea un CSV de ejemplo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4629db3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------------------------------+------+\n",
      "|review_id|user|review_text                        |rating|\n",
      "+---------+----+-----------------------------------+------+\n",
      "|1        |u01 |Excelente producto, muy recomendado|5     |\n",
      "|2        |u02 |Malo, se rompió a los dos días     |1     |\n",
      "|3        |u03 |Cumple con lo esperado             |4     |\n",
      "|4        |u04 |No me gustó la calidad del material|2     |\n",
      "|5        |u05 |Precio justo y buena atención      |5     |\n",
      "+---------+----+-----------------------------------+------+\n",
      "\n",
      "root\n",
      " |-- review_id: integer (nullable = true)\n",
      " |-- user: string (nullable = true)\n",
      " |-- review_text: string (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "input_path = Path(\"reviews.csv\")\n",
    "\n",
    "if not input_path.exists():\n",
    "    rows = [\n",
    "        (\"r001\", \"Excelente servicio y rápida entrega. Muy recomendado.\"),\n",
    "        (\"r002\", \"El producto llegó dañado, pero el soporte respondió a tiempo.\"),\n",
    "        (\"r003\", \"Calidad precio adecuado. Volvería a comprar.\"),\n",
    "        (\"r004\", \"No cumplió mis expectativas.\"),\n",
    "        (\"r005\", \"Todo bien.\"),\n",
    "        (\"r006\", \"Atención al cliente excepcional y envío en 24 horas.\"),\n",
    "        (\"r007\", \"No me gustó el empaque; recomendaría mejorar.\"),\n",
    "        (\"r008\", \"Muy útil, fácil de usar y con buen manual.\"),\n",
    "        (\"r009\", \"Precio alto para lo que ofrece.\"),\n",
    "        (\"r010\", \"Cinco estrellas. Superó mis expectativas.\"),\n",
    "        (\"r011\", \"Malo.\"),\n",
    "        (\"r012\", \"Regular. Se puede mejorar.\"),\n",
    "        (\"r013\", \"Entrega tardía, pero producto excelente.\"),\n",
    "        (\"r014\", \"Bonito diseño y buena batería.\"),\n",
    "        (\"r015\", \"Demasiado pesado para uso diario.\"),\n",
    "        (\"r016\", \"Funciona como se esperaba.\"),\n",
    "        (\"r017\", \"No funciona con mi sistema operativo.\"),\n",
    "        (\"r018\", \"La app companion es muy buena.\"),\n",
    "        (\"r019\", \"Me encantó, comprare otra unidad.\"),\n",
    "        (\"r020\", \"Servicio técnico resolvió mi problema en minutos.\")\n",
    "    ]\n",
    "    with input_path.open(\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"review_id\",\"review_text\"])\n",
    "        w.writerows(rows)\n",
    "    print(\"Se creó un CSV de ejemplo en\", input_path.resolve())\n",
    "\n",
    "# Cargar el CSV con Spark\n",
    "df = (spark.read\n",
    "      .option(\"header\", True)\n",
    "      .option(\"inferSchema\", True)\n",
    "      .csv(str(input_path)))\n",
    "\n",
    "df.show(5, truncate=False)\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4413bd",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Definir **UDF** `contar_palabras` y aplicarla\n",
    "\n",
    "La UDF corre en proceso Python por partición. Con la configuración anterior, debería funcionar correctamente en Windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "157a5d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------------------------------+------+------------+\n",
      "|review_id|user|review_text                        |rating|num_palabras|\n",
      "+---------+----+-----------------------------------+------+------------+\n",
      "|1        |u01 |Excelente producto, muy recomendado|5     |4           |\n",
      "|2        |u02 |Malo, se rompió a los dos días     |1     |7           |\n",
      "|3        |u03 |Cumple con lo esperado             |4     |4           |\n",
      "|4        |u04 |No me gustó la calidad del material|2     |7           |\n",
      "|5        |u05 |Precio justo y buena atención      |5     |5           |\n",
      "+---------+----+-----------------------------------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def contar_palabras(s: str) -> int:\n",
    "    if s is None:\n",
    "        return 0\n",
    "    # separa por espacios, ignora tokens vacíos\n",
    "    return len([t for t in s.split() if t.strip()])\n",
    "\n",
    "udf_contar_palabras = udf(contar_palabras, IntegerType())\n",
    "\n",
    "df2 = df.withColumn(\"num_palabras\", udf_contar_palabras(col(\"review_text\")))\n",
    "df2.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd145d",
   "metadata": {},
   "source": [
    "\n",
    "## 4) (Opcional) UDF que detecta presencia de palabras clave\n",
    "\n",
    "Ejemplo: marca `1` si encuentra alguna palabra de una lista de **keywords**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c81b1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+-----------------------------------+------+------------+-------------+\n",
      "|review_id|user|review_text                        |rating|num_palabras|flag_keywords|\n",
      "+---------+----+-----------------------------------+------+------------+-------------+\n",
      "|1        |u01 |Excelente producto, muy recomendado|5     |4           |1            |\n",
      "|2        |u02 |Malo, se rompió a los dos días     |1     |7           |1            |\n",
      "|3        |u03 |Cumple con lo esperado             |4     |4           |0            |\n",
      "|4        |u04 |No me gustó la calidad del material|2     |7           |0            |\n",
      "|5        |u05 |Precio justo y buena atención      |5     |5           |0            |\n",
      "+---------+----+-----------------------------------+------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "KEYWORDS = {\"excelente\",\"malo\",\"tardía\",\"rápida\",\"recomendado\",\"soporte\",\"dañado\",\"pesado\"}\n",
    "\n",
    "def contiene_keywords(s: str) -> int:\n",
    "    if not s:\n",
    "        return 0\n",
    "    txt = s.lower()\n",
    "    return 1 if any(k in txt for k in KEYWORDS) else 0\n",
    "\n",
    "from pyspark.sql.types import ShortType\n",
    "udf_contiene_keywords = udf(contiene_keywords, ShortType())\n",
    "\n",
    "df3 = df2.withColumn(\"flag_keywords\", udf_contiene_keywords(col(\"review_text\")))\n",
    "df3.show(truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
